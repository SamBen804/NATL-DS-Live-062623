{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to `keras` and `tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_digits, load_sample_images\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Learning Goals\n",
    "\n",
    "- Describe the concept of backpropagation\n",
    "- Explain the use of gradient descent in neural networks\n",
    "- Use `keras` to code up a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "flat_image = np.array(digits.data[0]).reshape(digits.data[0].shape[0], -1)\n",
    "eight_by_eight_image = digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eight_by_eight_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(eight_by_eight_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,\n",
    "                                                    digits.target,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z is the input from our collector, the sum of the weights\n",
    "# multiplied by the features and the bias\n",
    "\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    Input the sum of our weights times the pixel intensities, plus the bias\n",
    "    Output a number between 0 and 1.\n",
    "    \n",
    "    '''\n",
    "    return 1/(1+np.e**(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulation from last time\n",
    "\n",
    "w_1 = np.random.normal(0, 0.1, (X_train.shape[1], 1))\n",
    "w_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_1 = 0\n",
    "\n",
    "z_1 = X_train.dot(w_1) + b_1\n",
    "z_1\n",
    "\n",
    "output = sigmoid(z_1)\n",
    "y_pred = output > 0.5\n",
    "y_hat = y_pred.astype(int)\n",
    "y_hat[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation\n",
    "\n",
    "After a certain number of data points have been passed through the model, the weights will be *updated* with an eye toward optimizing our loss function. (Thinking back to biological neurons, this is like revising their activation potentials.) Typically, this is  done  by using some version of gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![bprop](images/BackProp_web.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Function Approximation\n",
    "\n",
    "[Neural networks are much like computational graphs](https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9).\n",
    "\n",
    "And computational graphs can be used [to approximate *any* function](http://neuralnetworksanddeeplearning.com/chap4.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Loss Function\n",
    "\n",
    "If we're thinking of networks, then, as function approximators, of course we'll want to know how good the approximation is. And so once again we have the idea of a [loss function](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html), which is of course what licenses our thinking of networks as models in the first place.\n",
    "\n",
    "Many loss functions are available. Your choice will depend in part on whether you're doing a regression or classification problem.\n",
    "\n",
    "Regression:\n",
    "\n",
    "- mean / median absolute error\n",
    "- mean / median squared error\n",
    "- [Huber loss](https://en.wikipedia.org/wiki/Huber_loss)\n",
    "\n",
    "Classification:\n",
    "\n",
    "- Crossentropy\n",
    "- [Hinge loss](https://en.wikipedia.org/wiki/Hinge_loss)\n",
    "- [Kullback-Leibler divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The loss function tells us how well our model performed by comparing the predictions to the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we train our models with `keras`, we will watch the loss function's progress across epochs.  A decreasing loss function will show us that our model is **improving**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The loss function is associated with the nature of our output. In logistic regression, our output was binary, so our loss function was the negative loglikelihood, aka **cross-entropy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ \\Large -\\ loglikelihood = -\\frac{1}{m} * \\sum\\limits_{i=1}^m y_i\\log{p_i} + (1-y_i)\\log(1-p_i) $$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 0, ..., 2, 7, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.43833394e-04, -7.43833394e-04, -7.43833394e-04, ...,\n",
       "        -7.43833394e-04, -7.20406537e+00, -7.20406537e+00],\n",
       "       [-1.07788926e-03, -1.07788926e-03, -1.07788926e-03, ...,\n",
       "        -1.07788926e-03, -6.83328944e+00, -6.83328944e+00],\n",
       "       [-1.22505043e-02, -1.22505043e-02, -1.22505043e-02, ...,\n",
       "        -1.22505043e-02, -4.40830718e+00, -4.40830718e+00],\n",
       "       ...,\n",
       "       [-2.04784400e-04, -2.04784400e-04, -2.04784400e-04, ...,\n",
       "        -2.04784400e-04, -8.49365523e+00, -8.49365523e+00],\n",
       "       [-2.80761040e-02, -2.80761040e-02, -2.80761040e-02, ...,\n",
       "        -2.80761040e-02, -3.58684166e+00, -3.58684166e+00],\n",
       "       [-1.77027163e-03, -1.77027163e-03, -1.77027163e-03, ...,\n",
       "        -1.77027163e-03, -6.33750729e+00, -6.33750729e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train*np.log(output) + (1-y_train) * np.log(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3493.8651802799773"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_ll = -1/len(y_train)*np.sum(y_train*np.log(output) + (1-y_train) * np.log(1-output))\n",
    "neg_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous variables, the loss function we have relied on is [MSE or MAE](http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/).\n",
    "\n",
    "Good [resource](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/) on backpropogation with RMSE loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here is a good summary of different [loss functions](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Gradient Descent, Epochs, and Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We not only use the the loss function to see how our model is improving; we also use it to update our parameters. The gradient of the loss function is calculated in relation to each parameter of our neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For a deep dive into the fitting process, reference Chapter 11 in [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Gradient descent can be performed in several different ways.  Unlike the `sklearn` implementation of linear regression, which finds the minimum of the loss with a closed form solution, neural networks move down the gradient **incrementally**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we fit our neural nets in Keras, we can set the hyperparameter `verbose` equal to 1, and we will see progress through **epochs**. Setting `verbose` to 2 will show just the epoch numbers as they progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "At the end of each epoch, **all examples** from our training set have passed through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of gradient descent update the parameters at different times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Batch Gradient Descent\n",
    "\n",
    "The gradient is calculated across all values.  We can find the direction of the gradient, and proceed directly towards the minimum.\n",
    "\n",
    "The weights are updated with regard to the cost at the **end of an epoch** after all training elements have passed through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "Updating the weights after all training examples have passed through can be detrimentally slow.  \n",
    "\n",
    "SGD updates the weights after each training **example**. SGD requires fewer epochs to achieve quality coefficients. This speeds up gradient descent [significantly](https://machinelearningmastery.com/gradient-descent-for-machine-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mini-Batch Gradient Descent\n",
    "\n",
    "In mini-batch, we pass a batch, calculate the gradient, update the params, then proceed to the next batch. It combines the advantages of batch and stochastic gradient descent: it is faster than SGD since the updates are not made with each point, and more computationally efficient than batch, since we don't have to hold all training examples in memory.\n",
    "\n",
    "[Good comparison of types of Gradient Descent and batch size](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Optimizers\n",
    "\n",
    "One of the levers we can tweak are the optimizers which control how the weights and biases are updated.\n",
    "\n",
    "For stochastic gradient descent, the weights are updated with a **constant** learning rate (alpha) after every record.  If we specify a batch size, the constant learning rate is multiplied by the gradient across the batch. \n",
    "\n",
    "Other optimizers, such as **Adam** (\"Adaptive Moment Estimation\"), update the weights in different ways. For Adam,\n",
    "> A learning rate is maintained for each network weight (parameter) and separately adapted as learning unfolds. See [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![backprop](images/ff-bb.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphic above can be a bit frustrating since it moves fast, but follow the progress as so:\n",
    "\n",
    "Forward propagation with the **blue** tinted arrows computes the output of each layer: i.e. a summation and activation.\n",
    "\n",
    "Backprop calculates the partial derivative (**green** circles) for each weight (**brown** line) and bias.\n",
    "\n",
    "Then the optimizer multiplies a **learning rate** ($\\eta$) to each partial derivative to calculate a new weight which will be applied to the next batch that passes through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a second, what is that warning? \n",
    "`Using TensorFlow backend.`\n",
    "\n",
    "<img align =left src=\"images/keras.png\"><br>\n",
    "\n",
    "### Keras is an API\n",
    "\n",
    "It can be layered on top of many different back-end processing systems.\n",
    "\n",
    "![kerasback](images/keras_tf_theano.png)\n",
    "\n",
    "While each of these systems has its own coding methods, `keras` abstracts from that in the streamlined Pythonic manner we are used to seeing in other Python modeling libraries.\n",
    "\n",
    "Keras development is backed primarily by Google, and the Keras API comes packaged in TensorFlow as tf.keras. Additionally, Microsoft maintains the CNTK Keras backend. Amazon AWS is maintaining the Keras fork with MXNet support. Other contributing companies include NVIDIA, Uber, and Apple (with CoreML).\n",
    "\n",
    "Theano has been discontinued.  The last release was 2017, but can still be used.\n",
    "\n",
    "We will use TensorFlow, as it is the most popular. TensorFlow became the most used Keras backend, and  eventually integrated Keras in via its `tf.keras` submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Building a Binary Classifier NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data.astype('float32')\n",
    "y = digits.target.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., ..., 8., 9., 8.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will start with a binary classification, and predict whether the number will be even or odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary = y % 2\n",
    "y_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Initialize a Linear Stack of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 10:35:48.936108: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-09-07 10:35:48.936196: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x158e20ee0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Add Densely Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x158e20ee0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Compile the Model\n",
    "\n",
    "The next step is new: After building the model we'll now **compile** it, which is a matter of yoking together the architecture with:\n",
    "- the optimizer we want to use,\n",
    "- the loss function we want to use, and\n",
    "- the metrics we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x158e20ee0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                780       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 893\n",
      "Trainable params: 893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fit the Model\n",
    "\n",
    "Now we're ready to **fit** it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 10:35:49.591876: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-09-07 10:35:49.741566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 4.3696 - accuracy: 0.5014\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2824 - accuracy: 0.4925\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6840 - accuracy: 0.4836\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2956 - accuracy: 0.4752\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0190 - accuracy: 0.4697\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8119 - accuracy: 0.4630\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6516 - accuracy: 0.4725\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5199 - accuracy: 0.4791\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4080 - accuracy: 0.4986\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3128 - accuracy: 0.5125\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2291 - accuracy: 0.5348\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1536 - accuracy: 0.5537\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0850 - accuracy: 0.5771\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0227 - accuracy: 0.5932\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9672 - accuracy: 0.6077\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9172 - accuracy: 0.6249\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8731 - accuracy: 0.6450\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8333 - accuracy: 0.6617\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7981 - accuracy: 0.6795\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7668 - accuracy: 0.6917\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7383 - accuracy: 0.7017\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7128 - accuracy: 0.7106\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.7212\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6669 - accuracy: 0.7307\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.7385\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.7440\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.7490\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5894 - accuracy: 0.7574\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5730 - accuracy: 0.7629\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.7685\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5424 - accuracy: 0.7724\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7752\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5154 - accuracy: 0.7774\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5029 - accuracy: 0.7841\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4911 - accuracy: 0.7874\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.7908\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7941\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4586 - accuracy: 0.7980\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.8002\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.8030\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.8075\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8125\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8158\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8214\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8258\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3869 - accuracy: 0.8308\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8358\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.8392\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3638 - accuracy: 0.8425\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3564 - accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159eb51c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y_binary, epochs=50, batch_size=1797, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 10:35:51.532803: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 8ms/step - loss: 0.2766 - accuracy: 0.8859\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.1912 - accuracy: 0.9182\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.1552 - accuracy: 0.9349\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.1309 - accuracy: 0.9477\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.1132 - accuracy: 0.9533\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0948 - accuracy: 0.9616\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9672\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0771 - accuracy: 0.9716\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0687 - accuracy: 0.9738\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9755\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0604 - accuracy: 0.9789\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0563 - accuracy: 0.9772\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0502 - accuracy: 0.9805\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0491 - accuracy: 0.9844\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9850\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9861\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0385 - accuracy: 0.9872\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9866\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9861\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9917\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9894\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9911\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9917\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0224 - accuracy: 0.9917\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0218 - accuracy: 0.9917\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9922\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0177 - accuracy: 0.9944\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0166 - accuracy: 0.9933\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0098 - accuracy: 0.9983\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0136 - accuracy: 0.9967\n",
      "Epoch 32/50\n",
      " 16/180 [=>............................] - ETA: 1s - loss: 0.0275 - accuracy: 0.9875  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-env-tensor/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y_binary, epochs=50, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Appendix: More on Tensorflow Vs. Keras\n",
    "\n",
    "\n",
    "### Let's start with tensors\n",
    "\n",
    "Tensors are multidimensional matrices.\n",
    "\n",
    "![tensor](images/tensors.png)\n",
    "\n",
    "### TensorFlow manages the flow of matrix math\n",
    "\n",
    "That makes neural network processing possible.\n",
    "\n",
    "![cat](images/cat-tensors.gif)\n",
    "\n",
    "For our numbers dataset, our tensors from the `sklearn` dataset were originally tensors of the shape 8x8, i.e. 64-bit pictures. Remember, that was with black and white images.\n",
    "\n",
    "For image processing, we are often dealing with color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = load_sample_images()['images'][0]\n",
    "\n",
    "imgplot = plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What do the dimensions of our image above represent?\n",
    "\n",
    "Tensors with higher numbers of dimensions have a higher **rank**.\n",
    "\n",
    "A matrix with rows and columns only, like the black and white numbers, has **rank 2**.\n",
    "\n",
    "A matrix with a third dimension, like the color pictures above, has **rank 3**.\n",
    "\n",
    "When we flatten an image by stacking the rows in a column, we are decreasing the rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_image = image.reshape(-1, 1)\n",
    "\n",
    "flat_image.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "427*640*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## TensorFlow has more levers and buttons, but Keras is more user-friendly\n",
    "\n",
    "Coding directly in **Tensorflow** allows you to tweak more parameters to optimize performance. The **Keras** wrapper makes the code more accessible for developers prototyping models.\n",
    "\n",
    "![levers](images/levers.jpeg)\n",
    "\n",
    "### Keras, an API with an intentional UX\n",
    "\n",
    "- Deliberately design end-to-end user workflows\n",
    "- Reduce cognitive load for your users\n",
    "- Provide helpful feedback to your users\n",
    "\n",
    "[full article here](https://blog.keras.io/user-experience-design-for-apis.html)<br>\n",
    "[full list of why to use Keras](https://keras.io/why-use-keras/)\n",
    "\n",
    "### A few comparisons\n",
    "\n",
    "While you **can leverage both**, here are a few comparisons.\n",
    "\n",
    "| Comparison | Keras | Tensorflow|\n",
    "|------------|-------|-----------|\n",
    "| **Level of API** | high-level API | High and low-level APIs |\n",
    "| **Speed** |  can *seem* slower |  is a bit faster |\n",
    "| **Language architecture** | simple architecture, more readable and concise | straight tensorflow is a bit more complex |\n",
    "| **Debugging** | less frequent need to debug | difficult to debug |\n",
    "| **Datasets** | usually used for small datasets | high performance models and large datasets that require fast execution|\n",
    "\n",
    "This is also a _**non-issue**_ - as you can leverage `tensorflow` commands within `keras` and vice versa. If Keras ever seems slower, it's because the developer's time is more expensive than the GPUs'. Keras is designed with the developer in mind. \n",
    "\n",
    "[reference link](https://www.edureka.co/blog/keras-vs-tensorflow-vs-pytorch/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-tensor",
   "language": "python",
   "name": "learn-env-tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
